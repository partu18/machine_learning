\subsection*{Estructura de los mails}
Quizás la parte más problemática, que nos hizo demorar mucho en el comienzo del proyecto fue la manera en la que estaban estructurados los emails. Una parte de éstos poseían símbolos que no pertenecían a la codificación \textbf{ascii} imposibilitándonos el procesamiento de ellos. La decisión que tomó el grupo fue ignorar estos símbolos y no tenerlos en cuenta.
Otro gran problema que se presentó fue el de la presencia de código HTML mal formado. Etiquetas que abrían pero nunca cerraban, o caracteres de espacio o '=' en otro encoding y deformando la estructura fue el ejemplo más concreto de este problema. Esto a su vez derivó en una dificultad de poder realizar un análisis de cuales son las etiquetas HTML más utilizadas en el HTML de SPAM vs HTML de HAM, ya que el parser identificaba como distintas etiquetas que en realidad, eran lo mismo. Una vez avanzado el tratamiento de los datos finalmente descartamos este análisis, ya que comparado con sólo el hecho de que un mail tenga o no HTML combinado con el texto, nos resultó haciendo un balance, mucho más significativo que el trabajo de analizar la frecuencia de etiquetas.

\subsection*{Árboles de decisión}
Quizás, otro de los problemas que nos encontramos, esta vez por un error que cometimos, fue la omisión del uso del parametro \textbf{random\_state} en la clasificación de árboles. Dicho parámetro, por default, hacía que alguna parte del algoritmo del clasificador sea random. Esto nos trajo problemas a la hora de querer volver a reproducir un clasificador antes generado, ya que las corridas no eran determinísticas. Para mitigar este problema, y aprovechando que la clasificación con árboles de decisión es de las más veloces, volvimos a realizar las pruebas de entrenamiento con los 4 datasets.

\subsection*{SVM}
El mayor problema que nos encontramos las querer evaluar el desempeño de un clasificador de SVM es el tiempo que demora en entrenar, evaluando sólo una combinación de datos, llegando este tiempo a ser superior a las 10 horas de procesamiento. Este problema fue mitigado de dos maneras. Como primera medida, en lugar de realizar un \textit{grid-search} extenso sobre los diferentes parámetros, solo hicimos las corridas con una única configuración, razonable en base a lo visto en clase y a una posterior investigación sobre las propiedades del método. Sin embargo esto no era suficiente, por lo que la otra medida que tomamos fue la de no entrenar con el 100\% de los datos sino de hacerlo solo con, aproximadamente, un 15\%  de los mismos. Este porcentaje puede variar según el dataset evaluado, ya que nos encontramos que para algunos dataset el entranamiento finalizaba en minutos, mientras que para otros, con la misma configuración pasaba a horas, entonces lo ajustábamos para lograr entrenar con un mayor porcentaje de los datos siempre y cuando el tiempo nos lo permita. 
Otro error cometido con SVM fue no darnos cuenta de reducir aun más la dimensionalidad ya que la misma la reducíamos a un espacio de 100 a 158 features. Dado que la complejidad algorítmica de SVM subyace en gran medida sobre la cantidad de features, esto podría haber sido una buena forma de conseguir mejor performance para SVM.
